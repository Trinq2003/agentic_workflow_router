{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "465dcc2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "# Use the current working directory to construct the src path, since __file__ is not defined in notebooks\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), \"..\", \"src\")))\n",
    "\n",
    "import json\n",
    "import time\n",
    "from pathlib import Path\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "from typing import List, Dict, Any, Tuple\n",
    "from dataclasses import dataclass\n",
    "import pandas as pd\n",
    "\n",
    "from data.data_loader import DataLoader, DataLoaderConfig, QueryData\n",
    "import logging\n",
    "\n",
    "logging.basicConfig(\n",
    "    level=logging.DEBUG,\n",
    "    format='%(asctime)s\\t%(name)s\\t%(levelname)s\\t%(message)s'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81ae3cc7",
   "metadata": {},
   "source": [
    "## Find time pattern in query logic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "769928e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from logic.nlp.find_time_pattern_in_query_logic import FindTimePatternInQueryLogic\n",
    "find_time_pattern_in_query_logic.forward(\"Ngưỡng Hiệu suất nâng cấp kết nối từng đối tác peering khác là bao nhiêu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "964a6e23",
   "metadata": {},
   "outputs": [],
   "source": [
    "find_time_pattern_in_query_logic.forward(\"Trong công thức tính Thermal Noise, k, T và B đại diện cho những gì?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee22957c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "Batch Test Script for FindTimePatternInQueryLogic\n",
    "\n",
    "This script:\n",
    "1. Loads data from dataset.xlsx using DataLoader\n",
    "2. Selects 200 queries for testing\n",
    "3. Runs FindTimePatternInQueryLogic on all queries in parallel\n",
    "4. Saves results to reports/test_result directory\n",
    "5. Generates comprehensive analysis and statistics\n",
    "\"\"\"\n",
    "\n",
    "from logic.nlp.find_time_pattern_in_query_logic import FindTimePatternInQueryLogic\n",
    "\n",
    "find_time_pattern_in_query_logic = FindTimePatternInQueryLogic()\n",
    "\n",
    "@dataclass\n",
    "class TestResult:\n",
    "    \"\"\"Structure for storing individual test results.\"\"\"\n",
    "    query: str\n",
    "    knowledge_domain: str\n",
    "    workers: List[str]\n",
    "    time_pattern_detected: bool\n",
    "    confidence_score: float\n",
    "    processing_time: float\n",
    "    original_index: int\n",
    "\n",
    "    def to_dict(self) -> Dict[str, Any]:\n",
    "        \"\"\"Convert to dictionary for JSON serialization.\"\"\"\n",
    "        return {\n",
    "            \"query\": self.query,\n",
    "            \"knowledge_domain\": self.knowledge_domain,\n",
    "            \"workers\": self.workers,\n",
    "            \"time_pattern_detected\": self.time_pattern_detected,\n",
    "            \"confidence_score\": self.confidence_score,\n",
    "            \"processing_time\": self.processing_time,\n",
    "            \"original_index\": self.original_index\n",
    "        }\n",
    "\n",
    "\n",
    "class BatchTimePatternTester:\n",
    "    \"\"\"\n",
    "    Batch tester for FindTimePatternInQueryLogic using DataLoader.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, data_path: str = \"../data/dataset.xlsx\", max_workers: int = 8):\n",
    "        \"\"\"\n",
    "        Initialize the batch tester.\n",
    "\n",
    "        Args:\n",
    "            data_path: Path to the Excel dataset\n",
    "            max_workers: Maximum number of parallel workers\n",
    "        \"\"\"\n",
    "        self.data_path = Path(data_path)\n",
    "        self.max_workers = max_workers\n",
    "        self.data_loader = None\n",
    "        self.time_logic = None\n",
    "        self.test_results: List[TestResult] = []\n",
    "\n",
    "        # Setup output directory\n",
    "        self.output_dir = Path(\"../reports/test_result\")\n",
    "        self.output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        logging.info(f\"Initialized BatchTimePatternTester with data path: {data_path}\")\n",
    "\n",
    "    def setup_components(self):\n",
    "        \"\"\"Setup DataLoader and FindTimePatternInQueryLogic.\"\"\"\n",
    "        logging.info(\"Setting up components...\")\n",
    "\n",
    "        # Setup DataLoader\n",
    "        config = DataLoaderConfig(\n",
    "            file_path=self.data_path,\n",
    "            max_workers=self.max_workers,\n",
    "            validate_data=True,\n",
    "            cache_enabled=True\n",
    "        )\n",
    "        self.data_loader = DataLoader(config)\n",
    "\n",
    "        # Setup Time Pattern Logic\n",
    "        self.time_logic = FindTimePatternInQueryLogic()\n",
    "\n",
    "        logging.info(\"Components setup completed\")\n",
    "\n",
    "    def load_and_select_queries(self, num_queries: int = 200, random_seed: int = 42) -> List[QueryData]:\n",
    "        \"\"\"\n",
    "        Load data and select queries for testing.\n",
    "\n",
    "        Args:\n",
    "            num_queries: Number of queries to select\n",
    "            random_seed: Random seed for reproducibility\n",
    "\n",
    "        Returns:\n",
    "            List[QueryData]: Selected queries for testing\n",
    "        \"\"\"\n",
    "        logging.info(f\"Loading data and selecting {num_queries} queries...\")\n",
    "\n",
    "        # Load all processed data\n",
    "        all_data = self.data_loader.get_processed_data()\n",
    "\n",
    "        # Convert to DataFrame for easier sampling\n",
    "        df = self.data_loader.to_dataframe()\n",
    "\n",
    "        if len(df) < num_queries:\n",
    "            logging.warning(f\"Dataset has only {len(df)} queries, using all available\")\n",
    "            num_queries = len(df)\n",
    "\n",
    "        # Sample queries\n",
    "        sampled_df = df.sample(n=num_queries, random_state=random_seed)\n",
    "\n",
    "        # Get the corresponding QueryData objects\n",
    "        selected_queries = []\n",
    "        sampled_indices = set(sampled_df['index'].tolist())\n",
    "\n",
    "        for query_data in all_data:\n",
    "            if query_data.index in sampled_indices:\n",
    "                selected_queries.append(query_data)\n",
    "\n",
    "        logging.info(f\"Selected {len(selected_queries)} queries for testing\")\n",
    "        return selected_queries\n",
    "\n",
    "    def run_single_test(self, query_data: QueryData) -> TestResult:\n",
    "        \"\"\"\n",
    "        Run time pattern detection on a single query.\n",
    "\n",
    "        Args:\n",
    "            query_data: QueryData object to test\n",
    "\n",
    "        Returns:\n",
    "            TestResult: Test result for this query\n",
    "        \"\"\"\n",
    "        start_time = time.time()\n",
    "\n",
    "        try:\n",
    "            # Run the time pattern detection\n",
    "            result_tensor = self.time_logic.forward(query_data.query)\n",
    "\n",
    "            # Extract results\n",
    "            detected = result_tensor.item() > 0.5\n",
    "            confidence = result_tensor.item()\n",
    "\n",
    "            processing_time = time.time() - start_time\n",
    "\n",
    "            return TestResult(\n",
    "                query=query_data.query,\n",
    "                knowledge_domain=query_data.knowledge_domain,\n",
    "                workers=query_data.workers,\n",
    "                time_pattern_detected=detected,\n",
    "                confidence_score=confidence,\n",
    "                processing_time=processing_time,\n",
    "                original_index=query_data.index\n",
    "            )\n",
    "\n",
    "        except Exception as e:\n",
    "            processing_time = time.time() - start_time\n",
    "            logging.error(f\"Error processing query {query_data.index}: {e}\")\n",
    "\n",
    "            return TestResult(\n",
    "                query=query_data.query,\n",
    "                knowledge_domain=query_data.knowledge_domain,\n",
    "                workers=query_data.workers,\n",
    "                time_pattern_detected=False,\n",
    "                confidence_score=0.0,\n",
    "                processing_time=processing_time,\n",
    "                original_index=query_data.index\n",
    "            )\n",
    "\n",
    "    def run_parallel_tests(self, queries: List[QueryData]) -> List[TestResult]:\n",
    "        \"\"\"\n",
    "        Run time pattern detection on all queries in parallel.\n",
    "\n",
    "        Args:\n",
    "            queries: List of QueryData objects to test\n",
    "\n",
    "        Returns:\n",
    "            List[TestResult]: List of test results\n",
    "        \"\"\"\n",
    "        logging.info(f\"Running parallel tests on {len(queries)} queries...\")\n",
    "\n",
    "        results = []\n",
    "        total_start_time = time.time()\n",
    "\n",
    "        with ThreadPoolExecutor(max_workers=self.max_workers) as executor:\n",
    "            # Submit all tasks\n",
    "            future_to_query = {\n",
    "                executor.submit(self.run_single_test, query): query\n",
    "                for query in queries\n",
    "            }\n",
    "\n",
    "            # Collect results as they complete\n",
    "            completed = 0\n",
    "            for future in as_completed(future_to_query):\n",
    "                try:\n",
    "                    result = future.result()\n",
    "                    results.append(result)\n",
    "                    completed += 1\n",
    "\n",
    "                    if completed % 50 == 0:\n",
    "                        logging.info(f\"Completed {completed}/{len(queries)} tests\")\n",
    "\n",
    "                except Exception as e:\n",
    "                    query = future_to_query[future]\n",
    "                    logging.error(f\"Failed to get result for query {query.index}: {e}\")\n",
    "\n",
    "        total_time = time.time() - total_start_time\n",
    "        logging.info(\".2f\")\n",
    "\n",
    "        return results\n",
    "\n",
    "    def save_results(self, results: List[TestResult], filename_prefix: str = \"time_pattern_test_200\"):\n",
    "        \"\"\"\n",
    "        Save test results to files.\n",
    "\n",
    "        Args:\n",
    "            results: List of TestResult objects\n",
    "            filename_prefix: Prefix for output filenames\n",
    "        \"\"\"\n",
    "        logging.info(f\"Saving results to {self.output_dir}...\")\n",
    "\n",
    "        # Convert results to dictionaries\n",
    "        results_dict = [result.to_dict() for result in results]\n",
    "\n",
    "        # Save as JSON\n",
    "        json_path = self.output_dir / f\"{filename_prefix}.json\"\n",
    "        with open(json_path, 'w', encoding='utf-8') as f:\n",
    "            json.dump(results_dict, f, ensure_ascii=False, indent=2)\n",
    "        logging.info(f\"Saved JSON results to {json_path}\")\n",
    "\n",
    "        # Save as CSV\n",
    "        csv_path = self.output_dir / f\"{filename_prefix}.csv\"\n",
    "        df = pd.DataFrame(results_dict)\n",
    "        df.to_csv(csv_path, index=False, encoding='utf-8')\n",
    "        logging.info(f\"Saved CSV results to {csv_path}\")\n",
    "\n",
    "    def generate_summary(self, results: List[TestResult]) -> Dict[str, Any]:\n",
    "        \"\"\"\n",
    "        Generate comprehensive summary statistics.\n",
    "\n",
    "        Args:\n",
    "            results: List of TestResult objects\n",
    "\n",
    "        Returns:\n",
    "            Dict[str, Any]: Summary statistics\n",
    "        \"\"\"\n",
    "        logging.info(\"Generating summary statistics...\")\n",
    "\n",
    "        if not results:\n",
    "            return {\"error\": \"No results to analyze\"}\n",
    "\n",
    "        # Basic statistics\n",
    "        total_queries = len(results)\n",
    "        detected_count = sum(1 for r in results if r.time_pattern_detected)\n",
    "        detection_rate = detected_count / total_queries if total_queries > 0 else 0\n",
    "\n",
    "        processing_times = [r.processing_time for r in results]\n",
    "        avg_processing_time = sum(processing_times) / len(processing_times)\n",
    "        max_processing_time = max(processing_times)\n",
    "        min_processing_time = min(processing_times)\n",
    "\n",
    "        # Confidence score statistics\n",
    "        confidence_scores = [r.confidence_score for r in results]\n",
    "        avg_confidence = sum(confidence_scores) / len(confidence_scores)\n",
    "        high_confidence_count = sum(1 for r in results if r.confidence_score > 0.8)\n",
    "        low_confidence_count = sum(1 for r in results if r.confidence_score < 0.2)\n",
    "\n",
    "        # Domain analysis\n",
    "        domain_stats = {}\n",
    "        for result in results:\n",
    "            domain = result.knowledge_domain\n",
    "            if domain not in domain_stats:\n",
    "                domain_stats[domain] = {\n",
    "                    \"total\": 0,\n",
    "                    \"detected\": 0,\n",
    "                    \"detection_rate\": 0.0\n",
    "                }\n",
    "            domain_stats[domain][\"total\"] += 1\n",
    "            if result.time_pattern_detected:\n",
    "                domain_stats[domain][\"detected\"] += 1\n",
    "\n",
    "        for domain in domain_stats:\n",
    "            stats = domain_stats[domain]\n",
    "            stats[\"detection_rate\"] = stats[\"detected\"] / stats[\"total\"] if stats[\"total\"] > 0 else 0\n",
    "\n",
    "        # Sample results\n",
    "        detected_samples = [r for r in results if r.time_pattern_detected][:5]\n",
    "        not_detected_samples = [r for r in results if not r.time_pattern_detected][:5]\n",
    "\n",
    "        summary = {\n",
    "            \"total_queries\": total_queries,\n",
    "            \"detected_count\": detected_count,\n",
    "            \"detection_rate\": detection_rate,\n",
    "            \"processing_time_stats\": {\n",
    "                \"average\": avg_processing_time,\n",
    "                \"max\": max_processing_time,\n",
    "                \"min\": min_processing_time,\n",
    "                \"total\": sum(processing_times)\n",
    "            },\n",
    "            \"confidence_stats\": {\n",
    "                \"average\": avg_confidence,\n",
    "                \"high_confidence_count\": high_confidence_count,\n",
    "                \"low_confidence_count\": low_confidence_count\n",
    "            },\n",
    "            \"domain_analysis\": domain_stats,\n",
    "            \"sample_detected_queries\": [\n",
    "                {\n",
    "                    \"query\": r.query[:100] + \"...\" if len(r.query) > 100 else r.query,\n",
    "                    \"domain\": r.knowledge_domain,\n",
    "                    \"confidence\": r.confidence_score\n",
    "                }\n",
    "                for r in detected_samples\n",
    "            ],\n",
    "            \"sample_not_detected_queries\": [\n",
    "                {\n",
    "                    \"query\": r.query[:100] + \"...\" if len(r.query) > 100 else r.query,\n",
    "                    \"domain\": r.knowledge_domain,\n",
    "                    \"confidence\": r.confidence_score\n",
    "                }\n",
    "                for r in not_detected_samples\n",
    "            ]\n",
    "        }\n",
    "\n",
    "        return summary\n",
    "\n",
    "    def save_summary(self, summary: Dict[str, Any], filename: str = \"time_pattern_test_summary_200.json\"):\n",
    "        \"\"\"Save summary statistics to file.\"\"\"\n",
    "        summary_path = self.output_dir / filename\n",
    "        with open(summary_path, 'w', encoding='utf-8') as f:\n",
    "            json.dump(summary, f, ensure_ascii=False, indent=2)\n",
    "        logging.info(f\"Saved summary to {summary_path}\")\n",
    "\n",
    "    def run_full_test(self, num_queries: int = 200):\n",
    "        \"\"\"\n",
    "        Run the complete test pipeline.\n",
    "\n",
    "        Args:\n",
    "            num_queries: Number of queries to test\n",
    "        \"\"\"\n",
    "        logging.info(\"Starting full batch time pattern test...\")\n",
    "\n",
    "        try:\n",
    "            # Setup components\n",
    "            self.setup_components()\n",
    "\n",
    "            # Load and select queries\n",
    "            selected_queries = self.load_and_select_queries(num_queries)\n",
    "\n",
    "            # Run parallel tests\n",
    "            test_results = self.run_parallel_tests(selected_queries)\n",
    "            self.test_results = test_results\n",
    "\n",
    "            # Save results\n",
    "            self.save_results(test_results)\n",
    "\n",
    "            # Generate and save summary\n",
    "            summary = self.generate_summary(test_results)\n",
    "            self.save_summary(summary)\n",
    "\n",
    "            # Print summary\n",
    "            print(\"\\n\" + \"=\"*60)\n",
    "            print(\"BATCH TIME PATTERN TEST RESULTS\")\n",
    "            print(\"=\"*60)\n",
    "            print(f\"Total queries tested: {summary['total_queries']}\")\n",
    "            print(f\"Time patterns detected: {summary['detected_count']}\")\n",
    "            print(\".1%\")\n",
    "            print(\".4f\")\n",
    "            print(f\"High confidence (>0.8): {summary['confidence_stats']['high_confidence_count']}\")\n",
    "            print(f\"Low confidence (<0.2): {summary['confidence_stats']['low_confidence_count']}\")\n",
    "            print(\"\\nTop domains by detection rate:\")\n",
    "            sorted_domains = sorted(\n",
    "                summary['domain_analysis'].items(),\n",
    "                key=lambda x: x[1]['detection_rate'],\n",
    "                reverse=True\n",
    "            )\n",
    "            for domain, stats in sorted_domains[:5]:\n",
    "                print(\".1%\")\n",
    "            print(\"\\nResults saved to: reports/test_result/\")\n",
    "\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error in full test: {e}\")\n",
    "            raise\n",
    "\n",
    "\n",
    "def main():\n",
    "    \"\"\"Main function to run the batch test.\"\"\"\n",
    "    # Create tester\n",
    "    tester = BatchTimePatternTester(max_workers=8)\n",
    "\n",
    "    # Run full test with 200 queries\n",
    "    tester.run_full_test(num_queries=200)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef28e7df",
   "metadata": {},
   "source": [
    "## Find syntax in query logic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b86a1e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "Test script to demonstrate DetectSyntaxInQueryLogic functionality\n",
    "\"\"\"\n",
    "from logic.nlp.detect_syntax_in_query_logic import DetectSyntaxInQueryLogic\n",
    "\n",
    "# Test the new 1x4 tensor output\n",
    "logic = DetectSyntaxInQueryLogic()\n",
    "\n",
    "test_cases = [\n",
    "    ('/remind me to call mom', [1.0, 0.0, 0.0, 0.0]),      # Only remind\n",
    "    ('please /task finish work', [0.0, 1.0, 0.0, 0.0]),     # Only task\n",
    "    ('use /tasks to organize', [0.0, 0.0, 1.0, 0.0]),      # Only tasks\n",
    "    ('schedule /meeting tomorrow', [0.0, 0.0, 0.0, 1.0]),  # Only meeting\n",
    "    ('/remind and /task both', [1.0, 1.0, 0.0, 0.0]),      # Both remind and task\n",
    "    ('no commands here', [0.0, 0.0, 0.0, 0.0]),            # None\n",
    "    ('/remind /task /meeting all', [1.0, 1.0, 0.0, 1.0]),  # Multiple commands\n",
    "]\n",
    "\n",
    "print('Testing 1x4 tensor output format:')\n",
    "print('=' * 60)\n",
    "print('Format: [remind, task, tasks, meeting]')\n",
    "print('-' * 60)\n",
    "\n",
    "for query, expected in test_cases:\n",
    "    result = logic.forward(query)\n",
    "    actual = result.tolist()\n",
    "\n",
    "    status = '✓' if actual == expected else '✗'\n",
    "    print(f'{status} \"{query}\"')\n",
    "    print(f'    Expected: {expected}')\n",
    "    print(f'    Actual:   {actual}')\n",
    "    print(f'    Tensor:   {result}')\n",
    "    print()\n",
    "\n",
    "print('Test completed!')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8413cb56",
   "metadata": {},
   "source": [
    "## Detect Human Feature In Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "075a73ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from logic.nlp.detect_human_feature_in_query_logic import DetectHumanFeatureInQueryLogic\n",
    "\n",
    "detect_human_feature_in_query_logic = DetectHumanFeatureInQueryLogic()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b809129b",
   "metadata": {},
   "outputs": [],
   "source": [
    "detect_human_feature_in_query_logic.forward(\"Tôi là Nguyen Quang Tri. Tôi đang làm việc tại Viettel\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc0945f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "detect_human_feature_in_query_logic.forward(\"Tôi là trinq12. Tôi đang làm việc tại Viettel\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "netmind",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
