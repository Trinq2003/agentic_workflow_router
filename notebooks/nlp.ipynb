{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "212704ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import logging\n",
    "\n",
    "logging.basicConfig(level=logging.DEBUG)\n",
    "\n",
    "# Use the current working directory to construct the src path, since __file__ is not defined in notebooks\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), \"..\", \"src\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64cd8c2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.nlp_models.underthesea import UndertheseaModel\n",
    "from models.config import NLPConfig\n",
    "\n",
    "model = UndertheseaModel(NLPConfig())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fcf269a",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"Thống kê số trạm Smallcell của Viettel tại Khu vực 1 năm 2025\"\n",
    "print(f\"Tokenize: {model.tokenize(query)}\")\n",
    "print(f\"POS Tag: {model.pos_tag(query)}\")\n",
    "print(f\"Extract Entities: {model.extract_entities(query)}\")\n",
    "print(f\"Analyze Sentiment: {model.analyze_sentiment(query)}\")\n",
    "print(f\"Parse Dependencies: {model.parse_dependencies(query)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fbefcdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming the provided code is saved in a file named `netmind_nlp.py`\n",
    "\n",
    "from pathlib import Path\n",
    "from models.nlp_processor import NLPProcessor, NLPTechnique\n",
    "\n",
    "# --- Test Functions ---\n",
    "\n",
    "def test_nlp_processor():\n",
    "    \"\"\"\n",
    "    Comprehensive test of the NLPProcessor class.\n",
    "    \"\"\"\n",
    "    print(\"--- Initializing NLPProcessor ---\")\n",
    "    try:\n",
    "        # Initialize the processor with the dummy config\n",
    "        processor = NLPProcessor(model_config_path=r\"..\\config\\nlp.yaml\")\n",
    "        print(\"✅ Processor initialized successfully.\")\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Initialization failed: {e}\")\n",
    "        return\n",
    "\n",
    "    # --- Test 1: Supported Languages & Techniques ---\n",
    "    print(\"\\n--- Test 1: Supported Languages & Techniques ---\")\n",
    "    supported_langs = processor.get_supported_languages()\n",
    "    available_techniques = processor.get_available_techniques()\n",
    "    print(f\"Supported Languages: {supported_langs}\")\n",
    "    print(f\"Available Techniques: {available_techniques}\")\n",
    "\n",
    "    # --- Test 2: English Text Processing ---\n",
    "    print(\"\\n--- Test 2: English Text Processing ---\")\n",
    "    english_text = \"Google's Gemini is a powerful large language model. It's revolutionizing the way we interact with information.\"\n",
    "    print(f\"Input Text: '{english_text}'\")\n",
    "\n",
    "    english_result = processor.process_text(\n",
    "        english_text,\n",
    "        techniques=[\n",
    "            NLPTechnique.TOKENIZATION,\n",
    "            NLPTechnique.POS_TAGGING,\n",
    "            NLPTechnique.SENTIMENT_ANALYSIS,\n",
    "            NLPTechnique.NAMED_ENTITY_RECOGNITION\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    print(f\"Detected Language: {english_result.language}\")\n",
    "    print(f\"Processing Time: {english_result.processing_time:.4f}s\")\n",
    "    print(\"Tokens:\", english_result.tokens)\n",
    "    print(\"POS Tags:\", english_result.pos_tags)\n",
    "    print(\"Sentiment:\", english_result.sentiment)\n",
    "    print(\"Entities:\", english_result.entities)\n",
    "\n",
    "    # --- Test 3: Vietnamese Text Processing ---\n",
    "    print(\"\\n--- Test 3: Vietnamese Text Processing ---\")\n",
    "    vietnamese_text = \"Hôm nay, thời tiết ở Hà Nội rất đẹp. Tôi muốn đi chơi.\"\n",
    "    print(f\"Input Text: '{vietnamese_text}'\")\n",
    "\n",
    "    vietnamese_result = processor.process_text(\n",
    "        vietnamese_text,\n",
    "        techniques=[\n",
    "            NLPTechnique.TOKENIZATION,\n",
    "            NLPTechnique.LEMMATIZATION,\n",
    "            NLPTechnique.NAMED_ENTITY_RECOGNITION\n",
    "        ]\n",
    "    )\n",
    "    print(f\"Detected Language: {vietnamese_result.language}\")\n",
    "    print(f\"Processing Time: {vietnamese_result.processing_time:.4f}s\")\n",
    "    print(\"Tokens:\", vietnamese_result.tokens)\n",
    "    print(\"Lemmas:\", vietnamese_result.lemmas)\n",
    "    print(\"Entities:\", vietnamese_result.entities)\n",
    "\n",
    "\n",
    "    # --- Test 4: Comprehensive Analysis ---\n",
    "    print(\"\\n--- Test 4: Comprehensive Text Analysis ---\")\n",
    "    analysis_text = \"The company's new AI product, 'QuantumSphere,' achieved record sales in Q3.\"\n",
    "    analysis_result = processor.analyze_text_comprehensive(analysis_text)\n",
    "\n",
    "    print(f\"Input Text: '{analysis_text}'\")\n",
    "    print(f\"Language: {analysis_result.language}\")\n",
    "    print(f\"Word Count: {analysis_result.word_count}\")\n",
    "    print(f\"Average Word Length: {analysis_result.avg_word_length:.2f}\")\n",
    "    print(f\"Sentiment Score: {analysis_result.sentiment_score:.2f}\")\n",
    "    print(f\"Keywords: {analysis_result.keywords}\")\n",
    "    print(f\"Entities: {analysis_result.entities}\")\n",
    "    print(f\"Topics: {analysis_result.topics}\")\n",
    "    print(f\"Grammar Issues: {analysis_result.grammar_issues}\")\n",
    "\n",
    "    # --- Test 5: Batch Processing ---\n",
    "    print(\"\\n--- Test 5: Batch Processing ---\")\n",
    "    batch_texts = [\n",
    "        \"This is the first sentence.\",\n",
    "        \"And this is the second one.\",\n",
    "        \"Đây là câu thứ ba trong danh sách.\"\n",
    "    ]\n",
    "    batch_results = processor.batch_process(batch_texts)\n",
    "\n",
    "    for i, result in enumerate(batch_results):\n",
    "        print(f\"\\nResult {i+1}:\")\n",
    "        print(f\"Text: '{result.text}'\")\n",
    "        print(f\"Language: {result.language}\")\n",
    "        print(f\"Tokens: {result.tokens}\")\n",
    "\n",
    "    print(\"\\n--- All tests completed. ---\")\n",
    "\n",
    "# --- Run the tests ---\n",
    "if __name__ == \"__main__\":\n",
    "    test_nlp_processor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f53c366e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import nlp_processor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24b64c98",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp_processor.process_text(\"Thông tin thuê bao ()*-25-890248598^&(Q#^%(&^$*(%^*(&)*#%&) Offline chặn cắt tại Trung tâm Quỳnh Lưu tỉnh Nghệ An trong cơn bão số 5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecee0ef9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "netmind",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
